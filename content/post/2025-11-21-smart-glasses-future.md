+++
date = '2025-11-21T22:30:00+08:00'
draft = false
title = '关于XR行业和AI智能眼镜的一些观察'
image = '/images/covers/smart-glasses.jpg'
categories = ['科技观察']
tags = ['XR', 'Meta Ray-Ban', 'Vision Pro', '空间计算', 'AI智能眼镜']
+++

最近这几年，我一直在关注 XR 这个方向，其中就包括 AR（增强现实），VR（虚拟现实），MR（混合现实）以及以 Meta Ray-Ban 为代表的智能眼镜。因为我觉得这个方向不再是一个"未来概念"，而是一个正在发生的现实。

作为一个程序员和科技爱好者，我花了不少时间研究这个领域。这篇文章想分享一些我的观察和思考。

## 两条路径，一个目标

现在市场上有两个很有意思的产品：Meta Ray-Ban 和 Apple Vision Pro。乍一看它们完全不同——一个轻得像普通墨镜，一个重得像头盔；一个只要三百多美元，一个要三千多。

但我越研究越觉得，它们其实在做同一件事，只是路径相反。

Meta Ray-Ban 从最轻便的形态出发，慢慢往上加功能。现在它只有 50 克，能拍照、录音、语音 AI。最新推出的 Meta Ray-Ban Display 已经加上了单目显示屏和肌电手环，能实现更好的交互了，再下一代可能会有更强的芯片和双目显示。它一直在做加法，但必须保证重量不能失控。

Vision Pro 则相反，从功能最完整的形态出发，往下做减法。现在它有 12 个摄像头、4K 分辨率、眼球追踪，但重达 650 克，续航只有 2 小时，还要外挂电池包。苹果接下来估计会砍传感器、降分辨率、换便宜材料，目标是把重量降到 300 克左右，价格降到 2000 美元以内。

这让我想起 iPhone 和 iPad 的关系。它们最终会在某个中间点相遇——一个既轻便又强大的设备，重量大概 150-200 克，续航能撑一整天，价格一千美元左右。

这个"中间点"我暂时也没办法预测到。

## Meta Ray-Ban 为什么卖得动？

说实话，一开始我没有很在意 Meta Ray-Ban。没有显示屏，功能那么少，谁会买？

但数据打脸了。依视路陆逊梯卡预测 2025 年能卖 400-500 万副，这已经不是小众产品了。

后来我想明白了几个点。

首先是品牌。如果叫"Meta Smart Glasses"，肯定死得很惨，只有极客会买。但它叫"Ray-Ban Meta"，这就不一样了。很多人本来就要买 Ray-Ban 墨镜，现在同样的价格，顺便有个智能功能，为什么不要？

其次是 Audio-First 的策略非常聪明。没有显示屏意味着省掉了最贵的零件（光波导镜片和光学模组），也不用担心续航和发热问题。更重要的是，没有漏光，社会接受度高——你戴着它别人不会觉得你在偷拍，拍摄的时候才会亮灯。

从技术角度看，Ray-Ban 其实把握住了多模态 AI 的红利期。它有第一视角摄像头（Vision）、立体声音频（Audio）、语音交互（Meta AI），这三个正好是 GPT-4o、Gemini 这些多模态大模型最擅长的场景。你拍张照片，问 AI 这是什么，它马上能告诉你。这种即时性是手机做不到的——手机要掏出来、解锁、打开 App、拍照，整个流程至少 10 秒。眼镜 2 秒就搞定。

当然，现在的 Ray-Ban 还很初级。真正的爆发点应该是成熟的 Display 版本发布之后——眼前能浮现字幕和箭头，那时候实时翻译、AR 导航这些场景才能真正落地。

## Vision Pro 的尴尬

Vision Pro 的技术确实很强。4K 分辨率、眼球追踪、手势识别，这些都是业界顶尖的。我戴过一次，那种沉浸感确实是 Quest 比不了的。

但它有个根本问题：使用场景不清晰。

苹果主打"空间办公"，说你可以在眼前摆很多虚拟屏幕。听起来很酷，但实际用起来问题很多。首先是重量，戴两个小时鼻梁和额头就开始疼。其次是续航，外挂个电池包还只能撑 2 小时。最关键的是，坐在桌子前，我为什么不直接用 MacBook 或者外接显示器？

我觉得 Vision Pro 的问题在于，它是一个技术展示品，而不是一个解决真实需求的产品。就像 2007 年的初代 iPhone，技术很惊艳，但真正起飞是在 iPhone 3G 和 App Store 推出之后。

Vision Pro 可能需要三到五代的迭代才能找到自己的位置。现在 50 万的年销量对苹果来说根本算不上成功（作为对比，初代 iPhone 卖了 610 万台）。

不过我倒是发现了一个 Vision Pro 可能的应用方向——具身智能的远程遥操作。

设想一下这个场景：你家里有个人形机器人，但它的 AI 还不够智能。这时候你可以雇一个远程操作员，TA 戴着 Vision Pro，通过网络连接到你家的机器人，看着机器人的第一视角视频（4K 高清），用手势控制机器人做家务。

这不是科幻。Tesla 的 Optimus、OpenAI 投资的 1X Technologies 都在用 VR 遥操作训练机器人。Vision Pro 的超高分辨率和精确手势识别，在这个场景下是真正的刚需——操作员要能看清螺丝的纹路，能精确控制拧瓶盖这种精细动作。

不过这个应用场景可能要等很久才会成熟，而且窗口期可能只有 5 年——之后机器人 AI 就足够强了，不再需要人类远程操作。

## 硬件的物理极限

研究智能眼镜的过程中，我越来越意识到，很多问题不是软件能解决的，而是受限于物理学。

最大的问题是能耗。锂电池的能量密度在过去十年几乎没有突破性进展，还是大概 250-300 Wh/kg。Ray-Ban Meta 只有 140 mAh 的电池（iPhone 的二十分之一），续航 4-6 小时。如果要加大电池，重量就会超过 60 克，鼻梁和耳朵会受不了。

这是一个"不可能三角"：轻便、续航、功能，只能选两个。

除非固态电池或者无线充电技术有突破，否则这个瓶颈很难解决。

第二个问题是光学。现在主流的方案是光波导（Waveguide），但这个技术有三个硬伤：光效率较低、视场角窄（大概 40-50 度，像透过小窗户看东西，最好的 Meta Orion 能做到 70 度）、成本高（Meta Orion 镜片使用的碳化硅单片成本非常高，良品率还很低）。

散热也是个大问题。眼镜不可能装风扇，只能被动散热。

还有交互方式。手机有触摸屏，VR 有手柄，但智能眼镜的"鼠标"在哪里？语音控制在公共场合很尴尬，手势识别手会酸，眼动追踪成本较高，触摸镜腿功能又太有限， 目前也只有 Meta Ray-Ban Display 的肌电手环和 Vision Pro 的眼动追踪能实现效果很好的交互。

这些都不是小问题，需要时间慢慢解决。

## 开发者的机会

作为程序员，我自然也在想，这个平台有什么开发机会。

目前最大的问题是 Meta 没有开放 Ray-Ban 的 SDK。你不能像开发 iOS App 那样直接在眼镜上跑代码。但这不意味着完全没法做。

一些开发者用了一个"黑客"方法：做手机端的 Companion App。用户用眼镜拍照或录音，数据自动同步到手机相册，你的 App 在后台监听，截获数据，调用 GPT-4o 之类的 AI 处理，然后通过系统通知把结果推回去。眼镜会自动播报通知内容，这样就完成了一次交互闭环。

比如你可以做个旅行翻译助手：拍菜单 → 识别日文 → 翻译成中文 → 告诉你小红书上的评价。或者做会议记录生成器：录音 → 转文字 →AI 总结关键点。

这种"绕路"的方式虽然不够优雅，但至少能用。而且我觉得 Meta 在 2026 年左右很可能会被迫开放 SDK，因为销量起来了之后，用户会抱怨"功能太少"，开发者也会疯狂敲门。

对比一下 iPhone 的历史：2007 年发布时是封闭系统，2008 年销量爆发后被迫开放 App Store。Ray-Ban 的轨迹可能很类似。

如果真的在 2026 年开放 SDK，那现在到 2027 年就是黄金窗口期。

技术栈方面，我觉得现在值得学的是：

- 多模态 AI 的 API 调用（GPT-4o Vision、Whisper、语音合成）
- RAG 和向量数据库（让 AI 能"记住"用户的历史）
- 原生移动开发（眼镜的大脑目前还是手机，需要深度集成蓝牙、相册、后台保活这些系统级功能，Web 或跨平台框架很难做好）

## 产业链的机会

虽然我不想推荐具体的股票，但从产业链角度看，智能眼镜确实是个值得关注的方向。

整个产业链大概可以分成几层：最上游是光学元件、AI 芯片、传感器这些核心零部件；中游是代工制造；下游是品牌和生态。

最稳的投资逻辑其实是找"卖铲人"——无论 Meta、苹果、Snap 谁最后赢了，供应链都会受益。比如做光学镜头的、做 AI 芯片的、做代工的。

不过现在 Vision Pro 的销量太小（50 万台对供应链来说是毛毛雨），主要的机会还是在 Ray-Ban 这条线上。如果今年真的卖出 500 万副，明年达到 1000 万副，供应链的弹性会很大。

时间节点上，我觉得 2026 年的财报季很关键，那时候能看出销量数据是不是真的达到了预期。如果确认了增长趋势,整个产业链都会被重新定价。

## 双寡头格局

综合来看，我觉得 2025-2030 年智能眼镜市场大概率会是 Meta 和苹果的双寡头格局。

Meta 有先发优势，Ray-Ban 品牌加持，销量领先。苹果技术领先，生态强大，但短期被价格拖累。Google 基本放弃了 C 端硬件，专心做 Android XR 平台，走授权路线。三星、小米这些会跟着 Google 的平台走，但很难有主动权。

为什么第三家很难弯道超车？主要有几个原因：

一是技术壁垒。光学、眼球追踪、手势识别这些都需要 5-10 年的积累，不是砸钱就能马上搞定的。

二是供应链绑定。核心供应商的产能基本被 Meta 和苹果买断了，新玩家即使有钱也抢不到产能。

三是生态护城河。Meta 有 2000 万 Quest 用户，苹果有 iOS 无缝迁移，新平台从零开始很难起来。

四是亏损承受能力。Meta 每年在 Reality Labs 亏 150 亿美元，股东还愿意支持，因为相信长期价值。其他公司的股东很难接受这种"无底洞"投入。

历史上看，"由下至上"（先普及再升级）的成功率远高于"由上至下"（先高端再降价）。从功能机到智能机、从微型机到 PC、从特斯拉 Model 3 到高端市场，都是这个规律。所以短期内我更看好 Meta 的路线，但长期苹果如果能把 Vision 降到 1500 美元，可能会后来居上。

最终可能会像现在的手机市场一样，iOS 和 Android 并存，各占一块。

## 一些碎碎念

写到这里突然想起一个细节。当年 iPhone 刚出来的时候，很多人也觉得"没有实体键盘怎么打字"、"触摸屏不如按键精准"。但后来证明，交互范式的改变会重新定义什么叫"好用"。

智能眼镜现在也面临类似的质疑：续航短、发热、交互不便。但说不定 5 年后回头看，这些都不算什么问题了。

另一个感受是，技术的演进速度其实没有我们想象的那么快。2012 年 Google Glass 发布时，大家以为 AR 眼镜马上就要普及了。结果十多年过去，我们才刚刚看到一点起色。硬件的迭代比软件慢太多，因为它受物理规律限制。

不过反过来说，正是因为慢,所以窗口期会更长。不像软件那样，一个爆款 App 可能三个月就被抄烂了。硬件和生态的护城河一旦建立起来，很难被颠覆。

最后，作为一个 INFJ-A，我还是倾向于观察而不是盲目行动。智能眼镜这个方向确实值得关注，但也不用太焦虑。技术的大趋势不会因为个人的参与与否而改变，我们能做的就是保持学习，等待合适的时机。

---

_这篇文章的观点仅代表个人思考，欢迎交流讨论。_
